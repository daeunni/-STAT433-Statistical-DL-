{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5. 자료증대와 이전학습.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "14J1SAOwqP2Vd2_oJAOnmvLzYWUfr6gss",
      "authorship_tag": "ABX9TyN2MciGMbcQzGHH1SZ7RlhC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nQHOEMjXMUf"
      },
      "source": [
        "# **Image Generator를 이용한 자료 증대**\n",
        "> 개와 고양이 분류하기 (with Generator, 이전학습, Fine tuning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV83kAdUyfax"
      },
      "source": [
        "# 관련 이미지가 들어있는 디렉토리 지정\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/DL/[STAT433] 딥러닝을 위한 통계적모델링/data/dogs and cats_small/train'\n",
        "validation_dir = '/content/drive/MyDrive/Colab Notebooks/DL/[STAT433] 딥러닝을 위한 통계적모델링/data/dogs and cats_small/validation'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VKhSOPPy1xk"
      },
      "source": [
        "## ImageDataGenerator \n",
        "- RGB, 정규화 등 사전정리가능\n",
        "- 배치 단위의 이미지 자료 생성기\n",
        "- 이미지 자료가 디렉토리에 있으면 flow_from_directory, 데이터프레임이면 flow_from_dataframe 함수 이용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbrMtM7oPxmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7634ca5e-85bb-4bdf-ffe3-0e2ca59dac5b"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "train_datagen=ImageDataGenerator(rescale=1./255)   # standardization (rescaling)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)   ## 뒤에서는 이 부분에 augmentation을 한다!\n",
        "\n",
        "# .flow_from_directory를 이용 \n",
        "train_generator=train_datagen.flow_from_directory(directory=train_dir,target_size=(150,150),\n",
        "                                                  batch_size=20,class_mode='binary')\n",
        "validation_generator=test_datagen.flow_from_directory(directory=validation_dir,target_size=(150,150),\n",
        "                                                      batch_size=20,class_mode='binary')\n",
        "# target_size로 (높이, 너비) 지정 = 픽셀의 크기\n",
        "# batch_size는 출력할 배치의 '크기'를 지정 (개수가 아님)\n",
        "# class_mode는 binary data로 지정"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1010 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGYQ1fTx0H3S"
      },
      "source": [
        "각각 train은 2000개, valid는 1000개 정도 되는 작은 데이터이다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOPbMEPbPzGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca6b1dca-3325-4c49-cd60-23ca2f3eddf7"
      },
      "source": [
        "# 제너레이터는 튜플을 출력함\n",
        "for x,y in train_generator:\n",
        "    print(x.shape)  # (배치, 높이, 너비, 채널)\n",
        "    print(y.shape)\n",
        "    break      # 반드시 break를 해야함(안하면 계속 반복됨)\n",
        "    \n",
        "#########이 부분은 학습에 필요 없는 부분임. 어차피 트테로 들어가는건 train_generator 객체임 ############"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 150, 150, 3)\n",
            "(20,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOQGxdh4lkY9",
        "outputId": "d908c550-e268-4a7b-9ca2-df64360ba243"
      },
      "source": [
        "print(x[0].shape, y.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 150, 3) (20,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxdSvW-BlzjE",
        "outputId": "126ba6da-1e21-4376-8fb7-a3e22486a050"
      },
      "source": [
        "y"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta6wHFuk0Nqy"
      },
      "source": [
        "## 1) Simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XTFxnt2PzDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c75266-50ec-4a04-b0ad-3378fd44eeb3"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense\n",
        "from tensorflow.keras import models\n",
        "cat_dog_model=models.Sequential()\n",
        "cat_dog_model.add(Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))  # training_generator에서 지정한 target_size\n",
        "cat_dog_model.add(MaxPooling2D(2,2))\n",
        "cat_dog_model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "cat_dog_model.add(MaxPooling2D(2,2))\n",
        "cat_dog_model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "cat_dog_model.add(MaxPooling2D(2,2))\n",
        "cat_dog_model.add(Flatten())\n",
        "cat_dog_model.add(Dense(512,activation='relu'))\n",
        "cat_dog_model.add(Dense(1,activation='sigmoid'))\n",
        "cat_dog_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 36992)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               18940416  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 19,034,177\n",
            "Trainable params: 19,034,177\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXjiXsTF0lxt"
      },
      "source": [
        "모수가 지금 매우매우 많은 상황이다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoo2q8AhPzA6"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt=optimizers.RMSprop(lr=1e-4)\n",
        "cat_dog_model.compile(loss='binary_crossentropy', optimizer=opt,metrics=['acc'])\n",
        "\n",
        "## fit_generator method 사용\n",
        "cat_dog_result=cat_dog_model.fit_generator(train_generator,  \n",
        "                                           steps_per_epoch=100,  # 1에폭당 몇개의 배치를 쓸 것인지?\n",
        "                                           # 앞서 지정한 배치의 크기는 20개, 데이터는 2000개므로 200개의 배치\n",
        "                                           epochs=10,\n",
        "                                           validation_data=validation_generator,  # validation_generator로 지정\n",
        "                                           validation_steps=50) \n",
        "                                           # 앞서 지정한 배치의 크기 20개, 데이터는 1000개이므로 50개의 배치 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d33Q5CltPy5z"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc=cat_dog_result.history['acc']\n",
        "val_acc=cat_dog_result.history['val_acc']\n",
        "loss=cat_dog_result.history['loss']\n",
        "val_loss=cat_dog_result.history['val_loss']\n",
        "epochs=range(1,len(acc)+1)\n",
        "plt.plot(epochs,acc,'b',label='training acc')\n",
        "plt.plot(epochs,val_acc,'bo',label='validation acc')\n",
        "plt.title('Simple CNN training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs,loss,'b',label='training loss')\n",
        "plt.plot(epochs,val_loss,'bo',label='validation loss')\n",
        "plt.title('Simple CNN training and validation loss')  # 많이 흔들리는걸 보면 별로 많이 좋지 않음(배치에 의존하고있다는 소리임)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQoP1P2W1uZN"
      },
      "source": [
        "오버피팅이 극심하게 발생함. 그 이유는 2000개의 자료에서 320만개의 모수를 추론하려고 했기 때문임\n",
        "> 1) 마지막 dense 층의 모수를 임의로 줄이거나 **regularization(L1)**을 출력층 전에 추가하여 해결 가능      \n",
        "\n",
        "\n",
        "> 2) 자료를 증대하여 해결 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhGfy5OQ2HwJ"
      },
      "source": [
        "## 2) Data Augmentation\n",
        "오버피팅 해결을 위한 데이터 증대"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z19b8Jpu1zXd",
        "outputId": "2fd3be9f-854b-4bd5-ce8f-536795bcf872"
      },
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=40, width_shift_range=0.2,  \n",
        "### 40으로 설정해서 independence를 보장하는 데이터를 만든다. random이 굉장히 중요한 개념이 된다\n",
        "                               height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,\n",
        "                                horizontal_flip=True, fill_mode='nearest')  # 빈 곳을 가장 가까운 데이터로 채운다 > 완전히 다른 이미지를 만듦\n",
        "\n",
        "# valid는 그대로 적용을 해야하니까 generate를 하지 않는다\n",
        "validation_datagen=ImageDataGenerator(rescale=1./255)  \n",
        "\n",
        "## 다시 flow_from_directory 이용\n",
        "train_generator=train_datagen.flow_from_directory(train_dir,target_size=(150,150),   \n",
        "                                              batch_size=32, class_mode='binary')\n",
        "validation_generator=train_datagen.flow_from_directory(validation_dir,target_size=(150,150),\n",
        "                                              batch_size=32, class_mode='binary')  \n",
        "# 배치사이즈에 의존하기 때문에 train, val의 배치사이즈는 같게하자!\n",
        "# 앞보다 배치사이즈를 32개 증가시켰다. "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1010 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivCo8HbB1zVZ",
        "outputId": "805beba3-2830-4bc8-f37a-591b0251359a"
      },
      "source": [
        "# 같은 오버피팅 유발 모델 똑같이 적합\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense, Dropout\n",
        "from tensorflow.keras import models\n",
        "aug_model=models.Sequential()\n",
        "aug_model.add(Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\n",
        "aug_model.add(MaxPooling2D(2,2))\n",
        "aug_model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "aug_model.add(MaxPooling2D(2,2))\n",
        "aug_model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "aug_model.add(MaxPooling2D(2,2))\n",
        "aug_model.add(Flatten())\n",
        "aug_model.add(Dropout(0.5))\n",
        "aug_model.add(Dense(512,activation='relu'))\n",
        "aug_model.add(Dense(1,activation='sigmoid'))\n",
        "aug_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 36992)             0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 36992)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               18940416  \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 19,034,177\n",
            "Trainable params: 19,034,177\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9bKjPAwPy3U"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "aug_model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4),metrics=['acc'])\n",
        "\n",
        "aug_result=cat_dog_model.fit_generator(train_generator,\n",
        "                                       steps_per_epoch=100,\n",
        "                                       epochs=10,\n",
        "                                       validation_data=validation_generator,\n",
        "                                       validation_steps=31)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_WuXk6ZPy0r"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc=aug_result.history['acc']\n",
        "val_acc=aug_result.history['val_acc']\n",
        "loss=aug_result.history['loss']\n",
        "val_loss=aug_result.history['val_loss']\n",
        "epochs=range(1,len(acc)+1)\n",
        "plt.plot(epochs,acc,'b',label='training acc')\n",
        "plt.plot(epochs,val_acc,'bo',label='validation acc')\n",
        "plt.title('training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs,loss,'b',label='training loss')\n",
        "plt.plot(epochs,val_loss,'bo',label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()   # 아직 많이 흔들리는걸로 보아 문제가 많이 있다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp8viQmW4UTD"
      },
      "source": [
        "자료증대를 통해 independent한 데이터를 늘림으로써 error를 추가해준 것임.      \n",
        "\n",
        "이는 uncertainty를 늘려 모형을 general 하게 만드는 바람직한 현상임"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QWPzLlV4nSW"
      },
      "source": [
        "## 3) 이전학습\n",
        "- 일반적인 vgg층 다음에 출력층을 추가하는 이전학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ql0x0sT4R-C",
        "outputId": "8a6abd57-b50e-4b3d-de27-a14852f6bbf1"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16  # vgg의 마지막 부분을 내 데이터에 맞게 고친다!! >> 오버피팅을 막자\n",
        "vgg_base=VGG16(weights='imagenet',include_top=False, input_shape=(150,150,3)) \n",
        "vgg_base.summary()  # 이미 training 되어있음"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YSGE9QnPyy9"
      },
      "source": [
        "# image data generator로 데이터 준비\n",
        "import numpy as np\n",
        "imagegen=ImageDataGenerator(rescale=1./255)  # 자료증대는 하지않음\n",
        "batch = 20\n",
        "\n",
        "def extract_features(directory,sample):\n",
        "    features=np.zeros(shape=(sample,4,4,512))  # vgg의 output만큼 0\n",
        "    labels=np.zeros(shape=(sample))\n",
        "\n",
        "    # flow_from_directory\n",
        "    generator=imagegen.flow_from_directory(directory,target_size=(150,150), batch_size=batch, class_mode='binary')  \n",
        "    i=0\n",
        "\n",
        "    # generator를 이용할 때는 배치단위이기 때문에 이렇게 vgg input을 받아야한다!\n",
        "    for batched_input, batched_label in generator:  # 각 배치별로 input, output 출력\n",
        "        \n",
        "        batched_features=vgg_base.predict(batched_input)  # 기존 vgg에 통과시킨다음 predict값 저장\n",
        "        \n",
        "        # vgg predict값을 넣음\n",
        "        features[ i*batch : (i+1)*batch]=batched_features\n",
        "        labels[ i*batch : (i+1)*batch]=batched_label\n",
        "        i+=1\n",
        "\n",
        "        if i*batch>=sample:\n",
        "            break\n",
        "\n",
        "    return features, labels"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-RkPalOPywh"
      },
      "source": [
        "train_input, train_labels=extract_features(train_dir,2000)  # 배치 20개씩 100번 반복\n",
        "validation_input, validation_labels=extract_features(validation_dir,1000)\n",
        "test_input, test_labels=extract_features(test_dir,1000)  # 배치 20개씩 50번 반복\n",
        "train_input.shape"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCj1e-YfnE4Z"
      },
      "source": [
        "VGG 뒤에 일반 이전학습 과정으로 MLP층과 출력층 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pxMasa1Pytm"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model1=Sequential()\n",
        "\n",
        "### 추가할 부분\n",
        "model1.add(Dense(256, activation='relu',input_dim=4*4*512))  # 너무 모수가 많기에 병목현상이 일어날 가능성이 크다\n",
        "model1.add(Dropout(0.5))  # 따라서 드랍아웃을 시킴\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model1.compile(optimizer=optimizers.RMSprop(lr=2e-5),loss='binary_crossentropy',metrics=['acc'])\n",
        "model1_result = model1.fit(train_features,train_labels, epochs=20,batch_size=20,validation_data=(validation_features,validation_labels))\n",
        "\n",
        "## 초기치가 랜덤이기 때문에, 초기치에 따라 수렴 속도가 달라진다. 껐다 다시돌렸는데 퍼포먼스가 많이 차이가 난다면 함수가 복잡하다는 뜻. \n",
        "## 따라서 에폭을 많이 돌려야함. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxtufkVhngdH"
      },
      "source": [
        "과적합문제가 많이 완화된 것을 볼 수 있다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F59oZwfwPyrH"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc=model1_result.history['acc']\n",
        "val_acc=model1_result.history['val_acc']\n",
        "loss=model1_result.history['loss']\n",
        "val_loss=model1_result.history['val_loss']\n",
        "epochs=range(1,len(acc)+1)\n",
        "plt.plot(epochs,acc,'b',label='training acc')\n",
        "plt.plot(epochs,val_acc,'bo',label='validation acc')\n",
        "plt.title('training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs,loss,'b',label='training loss')\n",
        "plt.plot(epochs,val_loss,'bo',label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX_VGQBSnqel"
      },
      "source": [
        "## 4) 이전학습 + 자료증대\n",
        "- VGG의 일부 모수는 고정하고, 새로운 은닉층을 추가하여 추가된 은닉층의 모수를 추정한다   \n",
        "(예전에는 그냥 VGG에 통과시킨 결과를 다른 모델에 넣었음)\n",
        "> 이 방법의 장점은 자료증대롤 사용할 수 있다는 것"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A2KuI4BPyos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f41a41e-d38e-41af-a69a-b4ce7dbe3a47"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "model_aug=Sequential()\n",
        "\n",
        "######### 우선 vgg 구조를 모델에 추가하기 ######\n",
        "model_aug.add(vgg_base)  # 여기에 아예 집어넣음 >> 근데 여기 파라미터는 freez 시켜야함.(아니면 2000개의 파라미터를 가지고 1400만개의 파라미터를 추정하는 꼴이 됨) 그럼 위 과정과 완전히 같아진다. \n",
        "model_aug.add(Flatten())\n",
        "model_aug.add(Dense(256,activation='relu'))\n",
        "model_aug.add(Dense(1,activation='sigmoid'))  # 드랍아웃을 안했기때문에 위 결과보다 나쁠수밖에 없음. \n",
        "model_aug.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 16,812,353\n",
            "Trainable params: 16,812,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYqXQSTov8WV"
      },
      "source": [
        "15개의 가중치그룹과 bias 그룹의 모수를 따로 추정하므로 이들을 모두 다하면 30이 됨.     \n",
        " (15개 = VGG16 13개 + 추가한 MLP 2개)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArZYOngQPymZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "449adf71-9092-4e9e-cd36-5617decc1258"
      },
      "source": [
        "print(len(model_aug.trainable_weights)) "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLEB47RoPykB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b905cfe-0223-47c2-eccd-df8a95cc6c51"
      },
      "source": [
        "# VGG의 모수가 다시 train 되지 않게 고정해야한다!!\n",
        "vgg_base.trainable=False  \n",
        "\n",
        "# ImageDataGenerator > 자료증대\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=40, width_shift_range=0.2,\n",
        "                               height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,\n",
        "                                horizontal_flip=True, fill_mode='nearest')  # train data의 자료를 늘린다(늘리고 엎고,,이런느낌)\n",
        "\n",
        "validation_datagen=ImageDataGenerator(rescale=1./255)   #검증데이터는 자료증대를 하지 않아야 함. 리스케일만 함\n",
        "\n",
        "\n",
        "# flow_from_directory\n",
        "train_generator=train_datagen.flow_from_directory(train_dir,target_size=(150,150),\n",
        "                                              batch_size=20, class_mode='binary')\n",
        "validation_generator=train_datagen.flow_from_directory(validation_dir,target_size=(150,150),\n",
        "                                              batch_size=20, class_mode='binary')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1010 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E7-uVWQkL0d"
      },
      "source": [
        "model_aug.compile(optimizer=optimizers.RMSprop(lr=2e-5),loss='binary_crossentropy',metrics=['acc'])\n",
        "model_aug_result=model_aug.fit_generator(train_generator,steps_per_epoch=200, epochs=20, validation_data=validation_generator,validation_steps=50)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_vSgbyvxKGj"
      },
      "source": [
        "과대적합은 어느정도 해결되고 있지만, 자료증대로 인해 노이즈가 추가되어 정밀도는 낮아진다. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtFyLyp-xgQg"
      },
      "source": [
        "## 5) Fine-Tuning\n",
        "- 지금까지 VGG층은 건든 적이 없지만(freeze), 미세조정으로 VGG의 conv 층을 trainable하게 바꾸고 그 뒤에 MLP까지 추가하여 새로운 맞춤형 모형을 만든다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlDY6_ILkLxi"
      },
      "source": [
        "vgg_base.trainable=True   # vgg 모수를 trainable하게 바꾼다!\n",
        "\n",
        "\n",
        "trainable_layer=False  \n",
        "\n",
        "# 레이어를 읽기 시작\n",
        "for layer in vgg_base.layers:  \n",
        "    if layer.name=='block5_conv1': # block5_conv1부터 trainable_layer가 True로 layer.trainable이 True로 바뀜\n",
        "        trainable_layer=True  # 쟤가 읽혀지면 True로 바꾸기. 그 다음부터는 True로 하고 trainiable하라는 뜻!\n",
        "\n",
        "    if trainable_layer:\n",
        "        layer.trainable=True \n",
        "\n",
        "    else:\n",
        "        layer.trainable=False"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYK2kyhckLuc"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "model_aug.compile(optimizer=optimizers.RMSprop(lr=1e-5),loss='binary_crossentropy',metrics=['acc'])\n",
        "\n",
        "# 앞서 사용한 자료증대 + 이전학습 모형을 그대로 가져온다. 근데 단, conv net이 trainable된\n",
        "result_final=model_aug.fit_generator(train_generator,\n",
        "                                     steps_per_epoch=200, \n",
        "                                     epochs=30, \n",
        "                                     validation_data=validation_generator,\n",
        "                                     validation_steps=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaKzn_SJy6kp"
      },
      "source": [
        "미세조정결과 성능이 증가한다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWeD-SnbkLrz"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc=result_final.history['acc']\n",
        "val_acc=result_final.history['val_acc']\n",
        "loss=result_final.history['loss']\n",
        "val_loss=result_final.history['val_loss']\n",
        "epochs=range(1,len(acc)+1)\n",
        "plt.plot(epochs,acc,'b',label='training acc')\n",
        "plt.plot(epochs,val_acc,'bo',label='validation acc')\n",
        "plt.title('training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs,loss,'b',label='training loss')\n",
        "plt.plot(epochs,val_loss,'bo',label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51V6S-jWkLWL"
      },
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "test_generator=test_datagen.flow_from_directory(test_dir,target_size=(150,150),\n",
        "                                              batch_size=20, class_mode='binary')\n",
        "loss, acc=model_aug.evaluate_generator(test_generator,steps=50)\n",
        "print(loss)\n",
        "print(acc)  # 2000개의 작은 데이터를 가지고 이전학습을 사용"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}