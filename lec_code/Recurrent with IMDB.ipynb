{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "ch9_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daeunni/Statistical_DL/blob/main/lec_code/Recurrent%20with%20IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4Sm7V87AXSM",
        "outputId": "2fcb652b-1131-4e3c-dbb8-159cf583b178"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "max_features=10000   # 10000개의 word를 가지고 하겠다\n",
        "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=max_features)\n",
        "print(type(x_train));print(type(x_test))\n",
        "print(type(y_train));print(type(y_test))\n",
        "print(x_train.shape)  # 25000개의 데이터\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "(25000,)\n",
            "(25000,)\n",
            "(25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6A9Kxf6AXTB",
        "outputId": "7ab16f3b-3ddc-4b13-9985-c8bc1ef3a38f"
      },
      "source": [
        "unique,count=np.unique(y_train,return_counts=True)   # 딕셔너리 형태로 unique와 count가 나온다\n",
        "print(dict(zip(unique,count)))  # zip으로 매핑시켜서 출력한다\n",
        "unique,count=np.unique(y_test,return_counts=True)\n",
        "print(dict(zip(unique,count)))   ### stratified sampling을 한 것임"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 12500, 1: 12500}\n",
            "{0: 12500, 1: 12500}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw4WR1-8AXTI",
        "outputId": "97bc537f-5106-4988-b8b1-7d48572f831b"
      },
      "source": [
        "print(x_train[0])\n",
        "print(len(x_train[0]))\n",
        "wordindex=imdb.get_word_index()\n",
        "print(len(wordindex))  # 218개의 length\n",
        "print(type(wordindex))\n",
        "for key,value in wordindex.items():\n",
        "    if value==1500:\n",
        "        print(key)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "218\n",
            "88584\n",
            "<class 'dict'>\n",
            "lacks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uLC7yyvAXTJ",
        "outputId": "65ede6b8-fafa-4461-f1fa-d4046f864cbd"
      },
      "source": [
        "exchindex=dict([(value,key) for (key,value) in wordindex.items()])\n",
        "review=''.join([exchindex.get(i-3,'!') for i in x_train[0]])  # join으로 떨어진 것들이 다 붙음\n",
        "print(review)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!thisfilmwasjustbrilliantcastinglocationscenerystorydirectioneveryone'sreallysuitedtheparttheyplayedandyoucouldjustimaginebeingthererobert!isanamazingactorandnowthesamebeingdirector!fathercamefromthesamescottishislandasmyselfsoilovedthefacttherewasarealconnectionwiththisfilmthewittyremarksthroughoutthefilmweregreatitwasjustbrilliantsomuchthatiboughtthefilmassoonasitwasreleasedfor!andwouldrecommendittoeveryonetowatchandtheflyfishingwasamazingreallycriedattheenditwassosadandyouknowwhattheysayifyoucryatafilmitmusthavebeengoodandthisdefinitelywasalso!tothetwolittleboy'sthatplayedthe!ofnormanandpaultheywerejustbrilliantchildrenareoftenleftoutofthe!listithinkbecausethestarsthatplaythemallgrownuparesuchabigprofileforthewholefilmbutthesechildrenareamazingandshouldbepraisedforwhattheyhavedonedon'tyouthinkthewholestorywassolovelybecauseitwastrueandwassomeone'slifeafterallthatwassharedwithusall\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSffphOgAXTT",
        "outputId": "dddf0b60-68e0-4c30-9d03-d30a3118088c"
      },
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "lenmax=700\n",
        "input_train=sequence.pad_sequences(x_train,maxlen=lenmax)  # pad_sequence를 진행(700개가 넘는건 잘라줌)\n",
        "input_test=sequence.pad_sequences(x_test,maxlen=lenmax) \n",
        "print(input_train.shape)\n",
        "print(input_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 700)\n",
            "(25000, 700)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QjJKzaPAXTY",
        "outputId": "f8ed76bb-2aaa-445e-9123-ada3f3df888f"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, SimpleRNN\n",
        "from tensorflow.keras.models import Sequential\n",
        "srnn=Sequential()\n",
        "srnn.add(Embedding(max_features,32, input_shape=700))  # 임베딩 (input length는 줘도되고 안줘도됨)\n",
        "## 700개가 된 것을 linear combination을 취함. \n",
        "## 32 dimension이 들어옴 (dim32가 xt가 됨)\n",
        "srnn.add(SimpleRNN(32))  # 32개의 x가 들어오고 이거의 linear combination을 취함\n",
        "srnn.add(Dense(1,activation='sigmoid'))  ### 파라미터 계산할 수 있어야함!!!\n",
        "srnn.summary()\n",
        "\n",
        "srnn.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
        "srnn.fit(input_train,y_train,epochs=10,batch_size=128)\n",
        "train_loss_acc=srnn.evaluate(input_train,y_train)\n",
        "test_loss_acc=srnn.evaluate(input_test,y_test)\n",
        "print(train_loss_acc)\n",
        "print(test_loss_acc)  # overfitting이 된 모습"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 32)          320000    \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 322,113\n",
            "Trainable params: 322,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\ysp\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 21s 851us/step - loss: 0.5341 - acc: 0.7275\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 21s 859us/step - loss: 0.3490 - acc: 0.8575\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 21s 857us/step - loss: 0.2900 - acc: 0.8850\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 21s 857us/step - loss: 0.2506 - acc: 0.9034\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 21s 853us/step - loss: 0.2241 - acc: 0.9154\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 21s 857us/step - loss: 0.1934 - acc: 0.9275\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 22s 863us/step - loss: 0.1715 - acc: 0.9380\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 22s 862us/step - loss: 0.1449 - acc: 0.9477\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 22s 861us/step - loss: 0.1191 - acc: 0.9572\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 21s 859us/step - loss: 0.0957 - acc: 0.9662\n",
            "25000/25000 [==============================] - 14s 559us/step\n",
            "25000/25000 [==============================] - 14s 556us/step\n",
            "[0.14247505063295365, 0.9520000219345093]\n",
            "[0.47568165253162387, 0.7996000051498413]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F1_WnEkAXTZ",
        "outputId": "325d45eb-1943-4635-aea2-23bf2520ab17"
      },
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "m_lstm=Sequential()\n",
        "m_lstm.add(Embedding(max_features,32)) \n",
        "m_lstm.add(LSTM(32))   # 2080의 4배\n",
        "m_lstm.add(Dense(1,activation='sigmoid'))\n",
        "m_lstm.summary()\n",
        "m_lstm.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
        "m_lstm.fit(input_train,y_train,epochs=10,batch_size=128)\n",
        "train_loss_acc=m_lstm.evaluate(input_train,y_train)\n",
        "test_loss_acc=m_lstm.evaluate(input_test,y_test)\n",
        "print(train_loss_acc)\n",
        "print(test_loss_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, None, 32)          320000    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 328,353\n",
            "Trainable params: 328,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\ysp\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 52s 2ms/step - loss: 0.4815 - acc: 0.7818\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 52s 2ms/step - loss: 0.2880 - acc: 0.8852\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 52s 2ms/step - loss: 0.2350 - acc: 0.9118\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 52s 2ms/step - loss: 0.2021 - acc: 0.9251\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 52s 2ms/step - loss: 0.1841 - acc: 0.9311\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 52s 2ms/step - loss: 0.1635 - acc: 0.9416\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 52s 2ms/step - loss: 0.1539 - acc: 0.9459\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 52s 2ms/step - loss: 0.1415 - acc: 0.9509\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 52s 2ms/step - loss: 0.1337 - acc: 0.9521\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 53s 2ms/step - loss: 0.1278 - acc: 0.9550\n",
            "25000/25000 [==============================] - 31s 1ms/step\n",
            "25000/25000 [==============================] - 28s 1ms/step\n",
            "[0.10286183683037758, 0.9681199789047241]\n",
            "[0.4097904998731613, 0.8678399920463562]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwrURrsyAXTk",
        "outputId": "25623523-7829-4df8-fd9d-6d65a94a6426"
      },
      "source": [
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.models import Sequential\n",
        "m_gru=Sequential()\n",
        "m_gru.add(Embedding(max_features,32))\n",
        "m_gru.add(GRU(32))  # 파라미터는 simple rnn의 3배\n",
        "m_gru.add(Dense(1,activation='sigmoid'))\n",
        "m_gru.summary()\n",
        "m_gru.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
        "m_gru.fit(input_train,y_train,epochs=10,batch_size=128)\n",
        "train_loss_acc=m_gru.evaluate(input_train,y_train)\n",
        "test_loss_acc=m_gru.evaluate(input_test,y_test)\n",
        "print(train_loss_acc)\n",
        "print(test_loss_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, None, 32)          320000    \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 32)                6240      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 326,273\n",
            "Trainable params: 326,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\ysp\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 64s 3ms/step - loss: 0.4769 - acc: 0.7598\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 64s 3ms/step - loss: 0.2899 - acc: 0.8812\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 64s 3ms/step - loss: 0.2409 - acc: 0.9069\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 64s 3ms/step - loss: 0.2116 - acc: 0.9203\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 64s 3ms/step - loss: 0.1935 - acc: 0.9271\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 64s 3ms/step - loss: 0.1757 - acc: 0.9360\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 64s 3ms/step - loss: 0.1625 - acc: 0.9409\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 66s 3ms/step - loss: 0.1479 - acc: 0.9474\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 66s 3ms/step - loss: 0.1432 - acc: 0.9496\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 66s 3ms/step - loss: 0.1338 - acc: 0.9532\n",
            "25000/25000 [==============================] - 30s 1ms/step\n",
            "25000/25000 [==============================] - 31s 1ms/step\n",
            "[0.09908104753017426, 0.9683200120925903]\n",
            "[0.3692723410415649, 0.8626800179481506]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1pYhGy8AXTm",
        "outputId": "ca1f3322-17f7-41c9-f4d9-9d5610dabead"
      },
      "source": [
        "from tensorflow.keras.layers import GRU, Embedding, Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "model=Sequential()\n",
        "model.add(Embedding(max_features,32))\n",
        "model.add(LSTM(32, dropout=0.3, recurrent_dropout=0.5, return_sequences=True))  # input은 h1부터 h700까지(return sequence를 True로 설정)\n",
        "# dropout은 lstm의 2개의 인풋 중 xt의 dropout을 시키는거고, recurrent_dropout은 ct(상태벡터)를 dropout시킴(ht를 dropout시키는게 아님)\n",
        "model.add(LSTM(64, dropout=0.5, recurrent_dropout=0.5))  # 700*32 = 64 combination이 됨\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.summary()\n",
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
        "model.fit(input_train,y_train,epochs=10,batch_size=128)\n",
        "\n",
        "#### 파라미터 개수 계산하는거 확인하기!!! 2장이랑 살펴보면서\n",
        "\n",
        "train_loss_acc=model.evaluate(input_train,y_train)\n",
        "test_loss_acc=model.evaluate(input_test,y_test)\n",
        "print(train_loss_acc)\n",
        "print(test_loss_acc)  # 시간이 오래걸림,,"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, None, 32)          320000    \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, None, 32)          8320      \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 353,217\n",
            "Trainable params: 353,217\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\ysp\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 221s 9ms/step - loss: 0.6021 - acc: 0.6617\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 235s 9ms/step - loss: 0.4202 - acc: 0.8203\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 241s 10ms/step - loss: 0.3588 - acc: 0.8493\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 243s 10ms/step - loss: 0.3242 - acc: 0.8664\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 242s 10ms/step - loss: 0.3042 - acc: 0.8780\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 241s 10ms/step - loss: 0.2836 - acc: 0.8891\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 242s 10ms/step - loss: 0.2680 - acc: 0.8956\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 242s 10ms/step - loss: 0.2574 - acc: 0.9024\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 243s 10ms/step - loss: 0.2444 - acc: 0.9072\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 242s 10ms/step - loss: 0.2305 - acc: 0.9150\n",
            "25000/25000 [==============================] - 169s 7ms/step\n",
            "25000/25000 [==============================] - 167s 7ms/step\n",
            "[0.19449921979904175, 0.9313200116157532]\n",
            "[0.3647528399848938, 0.8488399982452393]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teORQw0-AXTo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}