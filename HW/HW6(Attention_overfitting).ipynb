{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HW6(Attention overfitting).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daeunni/Statistical_DL/blob/main/HW/HW6(Attention_overfitting).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlPSATplHe_2"
      },
      "source": [
        "# **HW**\n",
        "### 1. attetion 모형의 overfitting 해결하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbZpxcZfN8oE"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2TfyCbaGv9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6508683f-522b-4bb5-cfa2-c3770f5dfe62"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATqji5eL4W4U"
      },
      "source": [
        "lines= pd.read_table('/content/drive/MyDrive/Colab Notebooks/DL/[STAT433] 딥러닝을 위한 통계적모델링/data/english to french.txt', names=['eng', 'fr'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agbkqAB3G_6Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "81ff1afe-b4fe-4979-dee3-3d8794b4bd42"
      },
      "source": [
        "lines.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Va !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    eng        fr\n",
              "0   Go.      Va !\n",
              "1  Run!   Cours !\n",
              "2  Run!  Courez !"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnoyhpsqXA9I",
        "outputId": "e00b244d-352c-4d4b-a380-3ca34f0c65a4"
      },
      "source": [
        "lines.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(149861, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_qXu5VX4XIp"
      },
      "source": [
        "lines = lines[0:50000]  # 5만 > 10만"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbnVTmwj1Tkl"
      },
      "source": [
        "# 1. Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkdgGL404XGc"
      },
      "source": [
        " # 소문자로 만들기 \n",
        "lines['eng']=lines['eng'].apply(lambda x: x.lower()) \n",
        "lines['fr']=lines['fr'].apply(lambda x: x.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOkzFxTe4fhL"
      },
      "source": [
        "# 문장부호 없애기\n",
        "exclude = set(string.punctuation)\n",
        "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))  \n",
        "lines.fr=lines.fr.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tVHM-oR4fpm"
      },
      "source": [
        "# start와 end를 추가한다!\n",
        "lines.fr = lines.fr.apply(lambda x : 'start '+ x + ' end')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D_AMqsdndne",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "7beda98d-88bf-4f10-b7bb-163dedd0b3bb"
      },
      "source": [
        "lines.head(3)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>go</td>\n",
              "      <td>start va  end</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>run</td>\n",
              "      <td>start cours  end</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>start courez  end</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   eng                 fr\n",
              "0   go      start va  end\n",
              "1  run   start cours  end\n",
              "2  run  start courez  end"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BByeGbi6rx89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18df5a6f-3421-4dd2-cce6-ec8d8c0924af"
      },
      "source": [
        "lines.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr9Nll0iHcrR"
      },
      "source": [
        "## 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCXv8Y7G_szR"
      },
      "source": [
        "# fit a tokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "def create_tokenizer(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y854XLW_swc"
      },
      "source": [
        "## 영어\n",
        "import json\n",
        "eng_tokenizer = create_tokenizer(lines['eng'])\n",
        "eng_dict=json.loads(json.dumps(eng_tokenizer.word_counts))  \n",
        "\n",
        "df =pd.DataFrame([eng_dict.keys(), eng_dict.values()]).T\n",
        "df.columns = ['word','count']\n",
        "df = df.sort_values(by='count',ascending = False)\n",
        "\n",
        "df['cum_count']=df['count'].cumsum()  # 단어 등장 빈도\n",
        "df['cum_perc'] = df['cum_count']/df['cum_count'].max()  # 단어 등장 비율\n",
        "final_eng_words = df[df['cum_perc']<0.8]['word'].values   # 상위 80퍼센트 등장한 단어만 사용"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_UfzxgyJUW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5ca42c-79c4-461e-bf63-66eb4480a2db"
      },
      "source": [
        "final_eng_words   # 80% 빈도수를 차지하는 총 영어 단어의 수 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['i', 'you', 'a', 'is', 'the', 'it', 'to', 'he', 'tom', 'im', 'me',\n",
              "       'do', 'are', 'this', 'that', 'dont', 'was', 'youre', 'we', 'not',\n",
              "       'my', 'have', 'your', 'did', 'be', 'were', 'all', 'she', 'its',\n",
              "       'they', 'like', 'can', 'what', 'go', 'of', 'in', 'very', 'want',\n",
              "       'no', 'how', 'here', 'him', 'on', 'cant', 'ill', 'thats', 'for',\n",
              "       'know', 'get', 'up', 'need', 'out', 'at', 'just', 'one', 'his',\n",
              "       'so', 'now', 'why', 'good', 'there', 'please', 'come', 'with',\n",
              "       'hes', 'think', 'has', 'too', 'will', 'her', 'love', 'see', 'got',\n",
              "       'look', 'help', 'am', 'really', 'us', 'had', 'who', 'right',\n",
              "       'take', 'didnt', 'well', 'let', 'where', 'theyre', 'an', 'feel',\n",
              "       'must', 'home', 'lets', 'stop', 'made', 'happy', 'back', 'about',\n",
              "       'ive', 'work', 'time', 'still', 'whats', 'give', 'going', 'may',\n",
              "       'never', 'them', 'tell', 'car', 'leave', 'alone', 'try', 'busy',\n",
              "       'could', 'say', 'went', 'saw', 'make', 'much', 'isnt', 'should',\n",
              "       'ready', 'money', 'keep', 'does', 'lost', 'dog', 'big', 'eat',\n",
              "       'wont', 'off', 'book', 'some', 'job', 'today', 'stay', 'down',\n",
              "       'bad', 'drink', 'everyone', 'again', 'been', 'tired', 'way',\n",
              "       'talk', 'old', 'door', 'hate', 'hear', 'as', 'day', 'id', 'wrong',\n",
              "       'enough', 'nice', 'call', 'toms', 'mary', 'lot', 'our', 'wait',\n",
              "       'sure', 'better', 'live', 'something', 'find', 'would', 'hard',\n",
              "       'hurt', 'hope', 'left', 'shes', 'open', 'gave', 'room', 'from',\n",
              "       'when', 'french', 'said', 'speak', 'new', 'house', 'yet', 'anyone',\n",
              "       'felt', 'everything', 'came', 'done', 'over', 'and', 'man', 'long',\n",
              "       'youve', 'read', 'fun', 'late', 'away', 'doing', 'wasnt', 'funny',\n",
              "       'bed', 'by', 'these', 'any', 'more', 'mine', 'water', 'name',\n",
              "       'friends', 'anything', 'told', 'ask', 'friend', 'believe', 'play',\n",
              "       'looks', 'everybody', 'show', 'always', 'great', 'thought', 'turn',\n",
              "       'heard', 'theres', 'only', 'doesnt', 'watch', 'nothing', 'cold',\n",
              "       'likes', 'took', 'cat', 'sorry', 'nobody', 'anybody', 'being',\n",
              "       'knew', 'both', 'life', 'trust', 'gone', 'teacher', 'remember',\n",
              "       'knows', 'true', 'yours', 'idea', 'sleep', 'careful', 'found',\n",
              "       'died', 'almost', 'use', 'already', 'if', 'wheres', 'put',\n",
              "       'mother', 'sick', 'married', 'school', 'best', 'father', 'safe',\n",
              "       'little', 'problem', 'tomorrow', 'hungry', 'glad', 'boy', 'close',\n",
              "       'buy', 'kind', 'than', 'arent', 'coming', 'miss', 'angry', 'sing',\n",
              "       'afraid', 'answer', 'ok', 'mean', 'tried', 'care', 'hurry',\n",
              "       'wanted', 'myself', 'run', 'walk', 'seems', 'lie', 'stupid',\n",
              "       'looked', 'broke', 'quit', 'early', 'enjoy', 'eyes', 'pretty',\n",
              "       'dead', 'soon', 'easy', 'loves', 'forget', 'ran', 'fast', 'met',\n",
              "       'beautiful', 'into', 'called', 'die', 'next', 'food', 'swim',\n",
              "       'sit', 'study', 'yourself', 'bicycle', 'lunch', 'word', 'shut',\n",
              "       'many', 'meet', 'else', 'pay', 'asked', 'talking', 'start', 'last',\n",
              "       'crazy', 'bring', 'two', 'wants', 'whos', 'hot', 'first',\n",
              "       'happened', 'agree', 'drunk', 'youd', 'win', 'wish', 'night',\n",
              "       'phone', 'proud', 'books', 'caught', 'yesterday', 'mind', 'upset',\n",
              "       'tv', 'plan', 'those', 'hand', 'working', 'understand', 'sad',\n",
              "       'wife', 'used', 'getting', 'bit', 'hat', 'bought', 'finished',\n",
              "       'liked', 'free', 'fine', 'english', 'coffee', 'often', 'handle',\n",
              "       'quite', 'light', 'own', 'young', 'hows', 'drive', 'tea', 'kids',\n",
              "       'someone', 'stand', 'music', 'guy'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5dVNOyvHsyu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9198ce4c-8b5d-4c70-f5a0-4296d17b05be"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>count</th>\n",
              "      <th>cum_count</th>\n",
              "      <th>cum_perc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>i</td>\n",
              "      <td>11307</td>\n",
              "      <td>11307</td>\n",
              "      <td>0.057204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>you</td>\n",
              "      <td>8787</td>\n",
              "      <td>20094</td>\n",
              "      <td>0.101659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>a</td>\n",
              "      <td>4899</td>\n",
              "      <td>24993</td>\n",
              "      <td>0.126444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>is</td>\n",
              "      <td>4468</td>\n",
              "      <td>29461</td>\n",
              "      <td>0.149048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>the</td>\n",
              "      <td>3808</td>\n",
              "      <td>33269</td>\n",
              "      <td>0.168313</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    word  count cum_count  cum_perc\n",
              "9      i  11307     11307  0.057204\n",
              "78   you   8787     20094  0.101659\n",
              "92     a   4899     24993  0.126444\n",
              "215   is   4468     29461  0.149048\n",
              "568  the   3808     33269  0.168313"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3OrR4k0AfTX"
      },
      "source": [
        "## 프랑스어\n",
        "fr_tokenizer = create_tokenizer(lines['fr'])\n",
        "fr_dict = json.loads(json.dumps(fr_tokenizer.word_counts))\n",
        "\n",
        "df =pd.DataFrame([fr_dict.keys(), fr_dict.values()]).T\n",
        "df.columns = ['word','count']\n",
        "df = df.sort_values(by='count',ascending = False)\n",
        "\n",
        "df['cum_count']=df['count'].cumsum()   # 단어 등장 빈도\n",
        "df['cum_perc'] = df['cum_count']/df['cum_count'].max()  # 단어 등장 비율\n",
        "final_fr_words = df[df['cum_perc']<0.8]['word'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klT6hK2fJSDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3a1984-7146-49b0-9338-e55ef231319b"
      },
      "source": [
        "final_fr_words    # 80% 빈도수를 차지하는 총 프랑스 단어의 수 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['start', 'end', 'je', 'pas', 'de', 'ne', 'vous', 'il', 'le', 'est',\n",
              "       'nous', 'la', 'à', 'tom', 'que', 'suis', 'un', 'cest', 'jai', 'tu',\n",
              "       'a', 'en', 'me', 'ce', 'une', 'les', 'ça', 'elle', 'tout', 'êtes',\n",
              "       'fait', 'sont', 'te', 'qui', 'mon', 'ma', 'faire', 'très',\n",
              "       'sommes', 'ils', 'des', 'nest', 'veux', 'es', 'estce', 'votre',\n",
              "       'du', 'se', 'pour', 'elles', 'y', 'bien', 'cela', 'moi', 'peux',\n",
              "       'comment', 'été', 'pourquoi', 'êtesvous', 'ici', 'besoin', 'ton',\n",
              "       'personne', 'où', 'avec', 'dans', 'plus', 'tous', 'vraiment',\n",
              "       'lui', 'lair', 'être', 'aller', 'si', 'cette', 'train', 'au',\n",
              "       'toi', 'trop', 'faut', 'nai', 'était', 'ai', 'monde', 'avons',\n",
              "       'son', 'pense', 'maintenant', 'astu', 'dit', 'ont', 'estu',\n",
              "       'avezvous', 'va', 'bon', 'cétait', 'puisje', 'toutes', 'sur',\n",
              "       'jaime', 'as', 'là', 'avez', 'ta', 'sest', 'encore', 'temps',\n",
              "       'sais', 'jamais', 'lai', 'on', 'fais', 'maison', 'quelle',\n",
              "       'jétais', 'comme', 'vais', 'vu', 'quel', 'sens', 'beaucoup',\n",
              "       'dois', 'mal', 'rien', 'voir', 'sil', 'peut', 'voiture', 'peu',\n",
              "       'ceci', 'porte', 'juste', 'ny', 'quelque', 'na', 'fort', 'soyez',\n",
              "       'toujours', 'chose', 'mes', 'quoi', 'estil', 'tes', 'deux', 'chez',\n",
              "       'quil', 'jadore', 'chien', 'sois', 'partir', 'bonne', 'plaît',\n",
              "       'questce', 'assez', 'nen', 'aujourdhui', 'sa', 'livre', 'et',\n",
              "       'atil', 'parler', 'travail', 'prie', 'déteste', 'dire', 'men',\n",
              "       'eu', 'heureux', 'viens', 'tellement', 'perdu', 'quand', 'dun',\n",
              "       'mieux', 'avoir', 'soit', 'jen', 'fut', 'seul', 'pris', 'déjà',\n",
              "       'quelquun', 'combien', 'simplement', 'notre', 'faites', 'raison',\n",
              "       'par', 'vos', 'aussi', 'pouvez', 'nêtes', 'peur', 'parle', 'dêtre',\n",
              "       'nouveau', 'avait', 'vie', 'sait', 'aije', 'confiance', 'occupé',\n",
              "       'entendu', 'ses', 'français', 'prêt', 'aime', 'connais', 'mary',\n",
              "       'prendre', 'ces', 'pouvons', 'manger', 'peuxtu', 'dune', 'naime',\n",
              "       'lit', 'regarde', 'daccord', 'homme', 'grand', 'arrête',\n",
              "       'pouvezvous', 'vrai', 'mort', 'père', 'mère', 'jespère', 'nom',\n",
              "       'même', 'idée', 'chambre', 'presque', 'faim', 'veuillez', 'trouve',\n",
              "       'fille', 'prends', 'semble', 'malade', 'merci', 'problème',\n",
              "       'nétait', 'tai', 'toute', 'pensais', 'peutêtre', 'reste',\n",
              "       'jaimerais', 'leau', 'demain', 'fatigué', 'heureuse', 'laissemoi',\n",
              "       'chanter', 'jy', 'dis', 'femme', 'garçon', 'aider', 'laissezmoi',\n",
              "       'venir', 'veut', 'non', 'enfants', 'nes', 'tête', 'chat', 'colère',\n",
              "       'gros', 'coup', 'aucun', 'aux', 'fini', 'dargent', 'pourrait',\n",
              "       'boulot', 'yeux', 'sans', 'vite', 'trouvé', 'nestce', 'tard',\n",
              "       'retard', 'fois', 'seule', 'journée', 'chance', 'crois', 'passé',\n",
              "       'lire', 'terminé', 'sûr', 'narrive', 'travaille', 'mauvais',\n",
              "       'nager', 'restez', 'laisse', 'veuxtu', 'travailler', 'allé',\n",
              "       'allez', 'arrêtez', 'bientôt', 'tôt', 'quiconque', 'main',\n",
              "       'rester', 'venu', 'doit', 'prenez', 'voulezvous', 'ami', 'sen',\n",
              "       'voulons', 'occupée', 'amis', 'hier', 'voici', 'point', 'estelle',\n",
              "       'tomber', 'verre', 'mourir', 'tort', 'difficile', 'froid',\n",
              "       'plutôt', 'heures', 'cet', 'vieux', 'grande', 'javais', 'devrais',\n",
              "       'pleurer', 'nuit', 'vis', 'demandé', 'prête', 'lécole', 'devez',\n",
              "       'vélo', 'aucune', 'acheté', 'parti', 'étaient', 'jeune', 'largent',\n",
              "       'mis', 'boire', 'chercher', 'ten', 'vois', 'vue', 'lheure',\n",
              "       'dautre'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYB8EkD_Ipvn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c765ebb0-33eb-4182-9cc3-1a8ac1f2dd7d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>count</th>\n",
              "      <th>cum_count</th>\n",
              "      <th>cum_perc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>start</td>\n",
              "      <td>50000</td>\n",
              "      <td>50000</td>\n",
              "      <td>0.158865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>end</td>\n",
              "      <td>50000</td>\n",
              "      <td>100000</td>\n",
              "      <td>0.31773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>je</td>\n",
              "      <td>9886</td>\n",
              "      <td>109886</td>\n",
              "      <td>0.34914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>pas</td>\n",
              "      <td>5758</td>\n",
              "      <td>115644</td>\n",
              "      <td>0.367435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>de</td>\n",
              "      <td>4663</td>\n",
              "      <td>120307</td>\n",
              "      <td>0.382251</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     word  count cum_count  cum_perc\n",
              "0   start  50000     50000  0.158865\n",
              "2     end  50000    100000   0.31773\n",
              "20     je   9886    109886   0.34914\n",
              "66    pas   5758    115644  0.367435\n",
              "75     de   4663    120307  0.382251"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4jrbgIjAfPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9353df3-a805-4f08-af43-d55349d42ea3"
      },
      "source": [
        " # 영어, 프랑스어에서 80%차지하는 unique한 단어 개수\n",
        "print('80% 차지하는 unique한 영어 단어 개수 : ', len(final_eng_words))\n",
        "print('80% 차지하는 unique한 프랑스 단어 개수 : ', len(final_fr_words)) \n",
        "\n",
        "### 80%에 해당하지 않는 단어는 unknown으로 하나의 단어 클래스로 한다. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80% 차지하는 unique한 영어 단어 개수 :  384\n",
            "80% 차지하는 unique한 프랑스 단어 개수 :  357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgZw9lw9J03y"
      },
      "source": [
        "따라서 머신 번역 문제는 385개의 영어 단어를 입력해 358개의 프랑스 단어를 구분하는 문제이다!       \n",
        "(class가 358개인 다중분류문제, categorical crossentropy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTOesHOq_ss0"
      },
      "source": [
        "# 위 80%에 해당하지 않는 단어는 unknown으로 전환한다!\n",
        "def filter_eng_words(x):\n",
        "  t = []\n",
        "  x = x.split()\n",
        "  for i in range(len(x)):\n",
        "    if x[i] in final_eng_words:\n",
        "      t.append(x[i])\n",
        "    else:\n",
        "      t.append('unk')  # unknown \n",
        "  x3 = ''\n",
        "  for i in range(len(t)):\n",
        "    x3 = x3+t[i]+' '   # 공백을 준다\n",
        "  return x3\n",
        "\n",
        "# 프랑스어 함수\n",
        "def filter_fr_words(x):\n",
        "  t = []\n",
        "  x = x.split()\n",
        "  for i in range(len(x)):\n",
        "    if x[i] in final_fr_words:\n",
        "      t.append(x[i])\n",
        "    else:\n",
        "      t.append('unk')\n",
        "  x3 = ''\n",
        "  for i in range(len(t)):\n",
        "    x3 = x3+t[i]+' '   # 공백을 준다\n",
        "  return x3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djQPLFAml-A3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a90aaa78-59e2-42f2-daf4-8e8230727101"
      },
      "source": [
        "filter_eng_words('he is extremely good')   # extremely > unk 변환! "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'he is unk good '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy6K2pdXCxhb"
      },
      "source": [
        "# unk설정 + 마지막 공백\n",
        "lines['eng']=lines['eng'].apply(filter_eng_words)\n",
        "lines['fr']=lines['fr'].apply(filter_fr_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFDBf_Zgxqrk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3ddd1e9a-e97e-423a-9932-b0392e1c62ba"
      },
      "source": [
        "lines.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>go</td>\n",
              "      <td>start va end</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>run</td>\n",
              "      <td>start unk end</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>start unk end</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unk</td>\n",
              "      <td>start ça unk end</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>unk</td>\n",
              "      <td>start au unk end</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    eng                 fr\n",
              "0   go       start va end \n",
              "1  run      start unk end \n",
              "2  run      start unk end \n",
              "3  unk   start ça unk end \n",
              "4  unk   start au unk end "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCO5WTo84fnn"
      },
      "source": [
        "# 유일한 영어와 프랑스어 집합\n",
        "all_eng_words=set()\n",
        "for eng in lines.eng:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "    \n",
        "all_french_words=set()\n",
        "for fr in lines.fr:\n",
        "    for word in fr.split():\n",
        "        if word not in all_french_words:\n",
        "            all_french_words.add(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCaP87KP4W_S"
      },
      "source": [
        "# 유일한 영어, 프랑스어 집합\n",
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_french_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_french_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgE2G1tsyyER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dd714d1-ca55-412f-ff42-d360596faf1a"
      },
      "source": [
        "print(input_words[10:20])  # 영어\n",
        "print(target_words[10:20])  # 프랑스어\n",
        "\n",
        "print(num_encoder_tokens, num_decoder_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['am', 'an', 'and', 'angry', 'answer', 'any', 'anybody', 'anyone', 'anything', 'are']\n",
            "['amis', 'arrête', 'arrêtez', 'as', 'assez', 'astu', 'atil', 'au', 'aucun', 'aucune']\n",
            "385 358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5eKtS1hnMob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0655b18a-fee0-425d-bbc9-c0d071fe7b9e"
      },
      "source": [
        "set(all_french_words) - set(final_fr_words)   # unknown 포함 여부 차이"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'unk'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-S77pDvkBp1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716bb066-18ce-4676-b7c9-fd34b42eec4a"
      },
      "source": [
        "print('unknown 포함 유일한 영어 집합 원소 개수 : ', len(input_words))\n",
        "print('unknown 포함 유일한 프랑스어 집합 원소 개수 : ', len(target_words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unknown 포함 유일한 영어 집합 원소 개수 :  385\n",
            "unknown 포함 유일한 프랑스어 집합 원소 개수 :  358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZQegvje4W8w"
      },
      "source": [
        "# 인덱스와 단어를 딕셔너리로 매핑\n",
        "input_token_index = dict(\n",
        "    [(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict(\n",
        "    [(word, i+1) for i, word in enumerate(target_words)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haKpA4AJhDnV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2aa403e-a397-464c-ca04-24d7583a8d31"
      },
      "source": [
        "input_token_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 1,\n",
              " 'about': 2,\n",
              " 'afraid': 3,\n",
              " 'again': 4,\n",
              " 'agree': 5,\n",
              " 'all': 6,\n",
              " 'almost': 7,\n",
              " 'alone': 8,\n",
              " 'already': 9,\n",
              " 'always': 10,\n",
              " 'am': 11,\n",
              " 'an': 12,\n",
              " 'and': 13,\n",
              " 'angry': 14,\n",
              " 'answer': 15,\n",
              " 'any': 16,\n",
              " 'anybody': 17,\n",
              " 'anyone': 18,\n",
              " 'anything': 19,\n",
              " 'are': 20,\n",
              " 'arent': 21,\n",
              " 'as': 22,\n",
              " 'ask': 23,\n",
              " 'asked': 24,\n",
              " 'at': 25,\n",
              " 'away': 26,\n",
              " 'back': 27,\n",
              " 'bad': 28,\n",
              " 'be': 29,\n",
              " 'beautiful': 30,\n",
              " 'bed': 31,\n",
              " 'been': 32,\n",
              " 'being': 33,\n",
              " 'believe': 34,\n",
              " 'best': 35,\n",
              " 'better': 36,\n",
              " 'bicycle': 37,\n",
              " 'big': 38,\n",
              " 'bit': 39,\n",
              " 'book': 40,\n",
              " 'books': 41,\n",
              " 'both': 42,\n",
              " 'bought': 43,\n",
              " 'boy': 44,\n",
              " 'bring': 45,\n",
              " 'broke': 46,\n",
              " 'busy': 47,\n",
              " 'buy': 48,\n",
              " 'by': 49,\n",
              " 'call': 50,\n",
              " 'called': 51,\n",
              " 'came': 52,\n",
              " 'can': 53,\n",
              " 'cant': 54,\n",
              " 'car': 55,\n",
              " 'care': 56,\n",
              " 'careful': 57,\n",
              " 'cat': 58,\n",
              " 'caught': 59,\n",
              " 'close': 60,\n",
              " 'coffee': 61,\n",
              " 'cold': 62,\n",
              " 'come': 63,\n",
              " 'coming': 64,\n",
              " 'could': 65,\n",
              " 'crazy': 66,\n",
              " 'day': 67,\n",
              " 'dead': 68,\n",
              " 'did': 69,\n",
              " 'didnt': 70,\n",
              " 'die': 71,\n",
              " 'died': 72,\n",
              " 'do': 73,\n",
              " 'does': 74,\n",
              " 'doesnt': 75,\n",
              " 'dog': 76,\n",
              " 'doing': 77,\n",
              " 'done': 78,\n",
              " 'dont': 79,\n",
              " 'door': 80,\n",
              " 'down': 81,\n",
              " 'drink': 82,\n",
              " 'drive': 83,\n",
              " 'drunk': 84,\n",
              " 'early': 85,\n",
              " 'easy': 86,\n",
              " 'eat': 87,\n",
              " 'else': 88,\n",
              " 'english': 89,\n",
              " 'enjoy': 90,\n",
              " 'enough': 91,\n",
              " 'everybody': 92,\n",
              " 'everyone': 93,\n",
              " 'everything': 94,\n",
              " 'eyes': 95,\n",
              " 'fast': 96,\n",
              " 'father': 97,\n",
              " 'feel': 98,\n",
              " 'felt': 99,\n",
              " 'find': 100,\n",
              " 'fine': 101,\n",
              " 'finished': 102,\n",
              " 'first': 103,\n",
              " 'food': 104,\n",
              " 'for': 105,\n",
              " 'forget': 106,\n",
              " 'found': 107,\n",
              " 'free': 108,\n",
              " 'french': 109,\n",
              " 'friend': 110,\n",
              " 'friends': 111,\n",
              " 'from': 112,\n",
              " 'fun': 113,\n",
              " 'funny': 114,\n",
              " 'gave': 115,\n",
              " 'get': 116,\n",
              " 'getting': 117,\n",
              " 'give': 118,\n",
              " 'glad': 119,\n",
              " 'go': 120,\n",
              " 'going': 121,\n",
              " 'gone': 122,\n",
              " 'good': 123,\n",
              " 'got': 124,\n",
              " 'great': 125,\n",
              " 'guy': 126,\n",
              " 'had': 127,\n",
              " 'hand': 128,\n",
              " 'handle': 129,\n",
              " 'happened': 130,\n",
              " 'happy': 131,\n",
              " 'hard': 132,\n",
              " 'has': 133,\n",
              " 'hat': 134,\n",
              " 'hate': 135,\n",
              " 'have': 136,\n",
              " 'he': 137,\n",
              " 'hear': 138,\n",
              " 'heard': 139,\n",
              " 'help': 140,\n",
              " 'her': 141,\n",
              " 'here': 142,\n",
              " 'hes': 143,\n",
              " 'him': 144,\n",
              " 'his': 145,\n",
              " 'home': 146,\n",
              " 'hope': 147,\n",
              " 'hot': 148,\n",
              " 'house': 149,\n",
              " 'how': 150,\n",
              " 'hows': 151,\n",
              " 'hungry': 152,\n",
              " 'hurry': 153,\n",
              " 'hurt': 154,\n",
              " 'i': 155,\n",
              " 'id': 156,\n",
              " 'idea': 157,\n",
              " 'if': 158,\n",
              " 'ill': 159,\n",
              " 'im': 160,\n",
              " 'in': 161,\n",
              " 'into': 162,\n",
              " 'is': 163,\n",
              " 'isnt': 164,\n",
              " 'it': 165,\n",
              " 'its': 166,\n",
              " 'ive': 167,\n",
              " 'job': 168,\n",
              " 'just': 169,\n",
              " 'keep': 170,\n",
              " 'kids': 171,\n",
              " 'kind': 172,\n",
              " 'knew': 173,\n",
              " 'know': 174,\n",
              " 'knows': 175,\n",
              " 'last': 176,\n",
              " 'late': 177,\n",
              " 'leave': 178,\n",
              " 'left': 179,\n",
              " 'let': 180,\n",
              " 'lets': 181,\n",
              " 'lie': 182,\n",
              " 'life': 183,\n",
              " 'light': 184,\n",
              " 'like': 185,\n",
              " 'liked': 186,\n",
              " 'likes': 187,\n",
              " 'little': 188,\n",
              " 'live': 189,\n",
              " 'long': 190,\n",
              " 'look': 191,\n",
              " 'looked': 192,\n",
              " 'looks': 193,\n",
              " 'lost': 194,\n",
              " 'lot': 195,\n",
              " 'love': 196,\n",
              " 'loves': 197,\n",
              " 'lunch': 198,\n",
              " 'made': 199,\n",
              " 'make': 200,\n",
              " 'man': 201,\n",
              " 'many': 202,\n",
              " 'married': 203,\n",
              " 'mary': 204,\n",
              " 'may': 205,\n",
              " 'me': 206,\n",
              " 'mean': 207,\n",
              " 'meet': 208,\n",
              " 'met': 209,\n",
              " 'mind': 210,\n",
              " 'mine': 211,\n",
              " 'miss': 212,\n",
              " 'money': 213,\n",
              " 'more': 214,\n",
              " 'mother': 215,\n",
              " 'much': 216,\n",
              " 'music': 217,\n",
              " 'must': 218,\n",
              " 'my': 219,\n",
              " 'myself': 220,\n",
              " 'name': 221,\n",
              " 'need': 222,\n",
              " 'never': 223,\n",
              " 'new': 224,\n",
              " 'next': 225,\n",
              " 'nice': 226,\n",
              " 'night': 227,\n",
              " 'no': 228,\n",
              " 'nobody': 229,\n",
              " 'not': 230,\n",
              " 'nothing': 231,\n",
              " 'now': 232,\n",
              " 'of': 233,\n",
              " 'off': 234,\n",
              " 'often': 235,\n",
              " 'ok': 236,\n",
              " 'old': 237,\n",
              " 'on': 238,\n",
              " 'one': 239,\n",
              " 'only': 240,\n",
              " 'open': 241,\n",
              " 'our': 242,\n",
              " 'out': 243,\n",
              " 'over': 244,\n",
              " 'own': 245,\n",
              " 'pay': 246,\n",
              " 'phone': 247,\n",
              " 'plan': 248,\n",
              " 'play': 249,\n",
              " 'please': 250,\n",
              " 'pretty': 251,\n",
              " 'problem': 252,\n",
              " 'proud': 253,\n",
              " 'put': 254,\n",
              " 'quit': 255,\n",
              " 'quite': 256,\n",
              " 'ran': 257,\n",
              " 'read': 258,\n",
              " 'ready': 259,\n",
              " 'really': 260,\n",
              " 'remember': 261,\n",
              " 'right': 262,\n",
              " 'room': 263,\n",
              " 'run': 264,\n",
              " 'sad': 265,\n",
              " 'safe': 266,\n",
              " 'said': 267,\n",
              " 'saw': 268,\n",
              " 'say': 269,\n",
              " 'school': 270,\n",
              " 'see': 271,\n",
              " 'seems': 272,\n",
              " 'she': 273,\n",
              " 'shes': 274,\n",
              " 'should': 275,\n",
              " 'show': 276,\n",
              " 'shut': 277,\n",
              " 'sick': 278,\n",
              " 'sing': 279,\n",
              " 'sit': 280,\n",
              " 'sleep': 281,\n",
              " 'so': 282,\n",
              " 'some': 283,\n",
              " 'someone': 284,\n",
              " 'something': 285,\n",
              " 'soon': 286,\n",
              " 'sorry': 287,\n",
              " 'speak': 288,\n",
              " 'stand': 289,\n",
              " 'start': 290,\n",
              " 'stay': 291,\n",
              " 'still': 292,\n",
              " 'stop': 293,\n",
              " 'study': 294,\n",
              " 'stupid': 295,\n",
              " 'sure': 296,\n",
              " 'swim': 297,\n",
              " 'take': 298,\n",
              " 'talk': 299,\n",
              " 'talking': 300,\n",
              " 'tea': 301,\n",
              " 'teacher': 302,\n",
              " 'tell': 303,\n",
              " 'than': 304,\n",
              " 'that': 305,\n",
              " 'thats': 306,\n",
              " 'the': 307,\n",
              " 'them': 308,\n",
              " 'there': 309,\n",
              " 'theres': 310,\n",
              " 'these': 311,\n",
              " 'they': 312,\n",
              " 'theyre': 313,\n",
              " 'think': 314,\n",
              " 'this': 315,\n",
              " 'those': 316,\n",
              " 'thought': 317,\n",
              " 'time': 318,\n",
              " 'tired': 319,\n",
              " 'to': 320,\n",
              " 'today': 321,\n",
              " 'told': 322,\n",
              " 'tom': 323,\n",
              " 'tomorrow': 324,\n",
              " 'toms': 325,\n",
              " 'too': 326,\n",
              " 'took': 327,\n",
              " 'tried': 328,\n",
              " 'true': 329,\n",
              " 'trust': 330,\n",
              " 'try': 331,\n",
              " 'turn': 332,\n",
              " 'tv': 333,\n",
              " 'two': 334,\n",
              " 'understand': 335,\n",
              " 'unk': 336,\n",
              " 'up': 337,\n",
              " 'upset': 338,\n",
              " 'us': 339,\n",
              " 'use': 340,\n",
              " 'used': 341,\n",
              " 'very': 342,\n",
              " 'wait': 343,\n",
              " 'walk': 344,\n",
              " 'want': 345,\n",
              " 'wanted': 346,\n",
              " 'wants': 347,\n",
              " 'was': 348,\n",
              " 'wasnt': 349,\n",
              " 'watch': 350,\n",
              " 'water': 351,\n",
              " 'way': 352,\n",
              " 'we': 353,\n",
              " 'well': 354,\n",
              " 'went': 355,\n",
              " 'were': 356,\n",
              " 'what': 357,\n",
              " 'whats': 358,\n",
              " 'when': 359,\n",
              " 'where': 360,\n",
              " 'wheres': 361,\n",
              " 'who': 362,\n",
              " 'whos': 363,\n",
              " 'why': 364,\n",
              " 'wife': 365,\n",
              " 'will': 366,\n",
              " 'win': 367,\n",
              " 'wish': 368,\n",
              " 'with': 369,\n",
              " 'wont': 370,\n",
              " 'word': 371,\n",
              " 'work': 372,\n",
              " 'working': 373,\n",
              " 'would': 374,\n",
              " 'wrong': 375,\n",
              " 'yesterday': 376,\n",
              " 'yet': 377,\n",
              " 'you': 378,\n",
              " 'youd': 379,\n",
              " 'young': 380,\n",
              " 'your': 381,\n",
              " 'youre': 382,\n",
              " 'yours': 383,\n",
              " 'yourself': 384,\n",
              " 'youve': 385}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdjR90537OVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b9435de-8481-4d45-b164-50124a8a8eb3"
      },
      "source": [
        "print(input_token_index['unk'])\n",
        "print(target_token_index['start'])\n",
        "print(target_token_index['end'])\n",
        "print(list(input_token_index.keys())[335])   # unknown은 336번으로 매핑"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "336\n",
            "284\n",
            "89\n",
            "unk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn8EDmXk7OVp"
      },
      "source": [
        "# RNN 시간스텝 정의를 위한 가장 긴 문장 찾기\n",
        "\n",
        "length_list=[]   # 영어\n",
        "for l in lines.eng:\n",
        "    length_list.append(len(l.split(' ')))\n",
        "eng_max_length = np.max(length_list)\n",
        "\n",
        "length_list=[]   # 프랑스어\n",
        "for l in lines.fr:\n",
        "    length_list.append(len(l.split(' ')))\n",
        "fr_max_length = np.max(length_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLKWQXq07OV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3cc08be-0e4c-4455-d8e2-d18651427d06"
      },
      "source": [
        "print(eng_max_length)   # 영어는 8개의 단어가 가장 긴 문장\n",
        "print(fr_max_length)    # 프랑스어는 17개의 단어가 가장 긴 문장"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5_mrLkj45gt"
      },
      "source": [
        "# Time step 기반 RNN Input data 생성(우선 zero로 shape만 맞춰서 생성함)\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(lines['eng']), eng_max_length),\n",
        "    dtype='float32')\n",
        "\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(lines['fr']), fr_max_length),\n",
        "    dtype='float32')\n",
        "\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(lines['fr']), fr_max_length, num_decoder_tokens+1),\n",
        "    dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrURv1JXrBDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2f4331-8a75-4d45-9c22-6f142fceaa3b"
      },
      "source": [
        "# 시간스텝(단어 수)와 5만개의 문장 수\n",
        "print(encoder_input_data.shape)\n",
        "print(decoder_input_data.shape)\n",
        "print(decoder_target_data.shape)   # 디코더는 358 + 1로 지정(index=0은 그냥 빈 공간으로 정의)\n",
        "# (표본, 시간스텝, 359개의 단어 원핫 벡터)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 8)\n",
            "(50000, 17)\n",
            "(50000, 17, 359)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v96r8est1yqA"
      },
      "source": [
        "- Encoder_input_data : 영어 문장 저장\n",
        "- Decoder_input_data : 영어 문장에 대응되는 프랑스어 문장\n",
        "- Decoder_target_data : Decoder_input_data보다 한 시점 앞서게 해서 번역을 예측문제로 전환\n",
        "\n",
        "> 현재 영어 단어와 프랑스어 단어로 다음에 오는 프랑스어 단어를 예측하는 문제가 된다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLu41cqb1Czj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "799ee218-f135-4382-eae2-b3b155d11640"
      },
      "source": [
        "encoder_input_data[3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km2HiJ0G45oB"
      },
      "source": [
        "# 데이터 직접 생성\n",
        "for i, (input_text, target_text) in enumerate(zip(lines['eng'], lines['fr'])):\n",
        "\n",
        "    for t, word in enumerate(input_text.split()):\n",
        "        encoder_input_data[i, t] = input_token_index[word]\n",
        "\n",
        "    for t, word in enumerate(target_text.split()):\n",
        "        decoder_input_data[i, t] = target_token_index[word]\n",
        "\n",
        "        if t>0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "\n",
        "            if t== len(target_text.split())-1:\n",
        "                decoder_target_data[i, t:, 89] = 1   # 0은 모두 89로 대체함 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFwjmRUe-EC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61cd4f55-73d0-48c1-968c-f10cd66c2e54"
      },
      "source": [
        "print(decoder_input_data.shape, encoder_input_data.shape, decoder_target_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 17) (50000, 8) (50000, 17, 359)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju3zZwus9kth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0deb11ee-ec0b-42f1-92f5-dca15b1523ac"
      },
      "source": [
        "decoder_input_data   # 0은 모두 end를 의미하는 89로 채움! "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[284., 321.,  89., ...,   0.,   0.,   0.],\n",
              "       [284., 320.,  89., ...,   0.,   0.,   0.],\n",
              "       [284., 320.,  89., ...,   0.,   0.,   0.],\n",
              "       ...,\n",
              "       [284., 127., 320., ...,   0.,   0.,   0.],\n",
              "       [284., 127., 320., ...,   0.,   0.,   0.],\n",
              "       [284.,  86., 320., ...,   0.,   0.,   0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syERbzcc-hC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38497635-6b86-44b1-8d78-dd74add0278c"
      },
      "source": [
        "encoder_input_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[120.,   0.,   0., ...,   0.,   0.,   0.],\n",
              "       [264.,   0.,   0., ...,   0.,   0.,   0.],\n",
              "       [264.,   0.,   0., ...,   0.,   0.,   0.],\n",
              "       ...,\n",
              "       [312., 120., 320., ..., 336.,   0.,   0.],\n",
              "       [312., 124., 162., ...,   0.,   0.,   0.],\n",
              "       [312., 124., 162., ...,   0.,   0.,   0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd_TzFXztDBQ"
      },
      "source": [
        "for i in range(decoder_input_data.shape[0]):\n",
        "    for j in range(decoder_input_data.shape[1]):\n",
        "        if(decoder_input_data[i][j]==0):\n",
        "            decoder_input_data[i][j] = 89"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgekjoPz1Ydk"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# 2. Attention\n",
        "- encoder output과 decoder 출력값의 유사성인 attention을 계산해 인코더에 가중치를 부여한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBoQwD7vlQcQ"
      },
      "source": [
        "# 원래..\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import dot\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Dropout, Activation, concatenate\n",
        "import tensorflow as tf\n",
        "# dropout 0.1 > 0.5\n",
        "\n",
        "\n",
        "################################ 인코더 #################################\n",
        "encoder_inputs = Input(shape=(eng_max_length,))\n",
        "en_x=  Embedding(num_encoder_tokens+1, 256)(encoder_inputs)  # 임베딩차원 늘림 \n",
        "en_x = Dropout(0.1)(en_x)   # dropout 추가\n",
        "encoder_outputs, state_h, state_c = LSTM(256, return_sequences=True, return_state=True)(en_x)\n",
        "encoder_states=[state_h, state_c]   \n",
        "\n",
        "################################ 디코더 #################################\n",
        "decoder_inputs = Input(shape=(fr_max_length,))\n",
        "dex=  Embedding(num_decoder_tokens+1,256)(decoder_inputs)\n",
        "decoder = Dropout(0.1)(dex)\n",
        "decoder = LSTM(256, return_sequences=True)(decoder, initial_state=encoder_states)   # 인코더 state와 연결!!\n",
        "\n",
        "\n",
        "################################ Attention Layer #################################\n",
        "t = Dense(1500, activation='tanh')(encoder_outputs)\n",
        "t1 = Dense(1500, activation='tanh')(decoder)\n",
        "\n",
        "# dot product attention (유사도를 구하는 방법)\n",
        "# attention 가중치를 value에 반영 (어텐션 score 계산) \n",
        "# > 인코더의 모든 은닉상태 각각이 디코더의 현 시점 은닉상태 St와 얼마나 유사한지를 score로 나타냄\n",
        "attention = dot([t1, t], axes=[2, 2])    # attention 가중치 계산 (Query와 Key의 유사도를 구함)\n",
        "\n",
        "attention = Dense(eng_max_length, activation='tanh')(attention)  \n",
        "attention = Activation('softmax')(attention)  # 가중치를 softmax 확률 값을 통해 인코더 output(value)에 전달!\n",
        "\n",
        "context = dot([attention, encoder_outputs], axes = [2,1])  # 어텐션 value(가중합, product, weighted sum)\n",
        "\n",
        "decoder_combined_context = concatenate([context, decoder])   # attention value와 디코더의 현재 은닉상태를 concat하여 하나의 벡터로 만듦 \n",
        "decoder_combined_context = Dense(1000, activation='tanh')(decoder_combined_context)\n",
        "# decoder = Dropout(0.5)()\n",
        "\n",
        "output = Dense( num_decoder_tokens+1, activation=\"softmax\")(decoder_combined_context)    # 출력층 (단어 확률값으로 출력)\n",
        "\n",
        "model3 = Model(inputs=[encoder_inputs, decoder_inputs], outputs=[output])\n",
        "\n",
        "\n",
        "## ,  kernel_regularizer=tf.keras.regularizers.L1(0.01) 안좋음 > train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-dKyqvjJFYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9348e9eb-5880-4843-8aee-5703d27ea2e6"
      },
      "source": [
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.layers import dot\n",
        "# from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Dropout, Activation, concatenate, BatchNormalization, GRU\n",
        "# import tensorflow as tf\n",
        "# # dropout 0.1 > 0.5\n",
        "# # recurrent dropout 안좋음 \n",
        "# # 임베딩차원 늘림  > 안좋음\n",
        "\n",
        "# # 노드 수 줄임\n",
        "# # initializer, batchnormal 추가\n",
        "# ################################ 인코더 #################################\n",
        "# encoder_inputs = Input(shape=(eng_max_length,))\n",
        "# en_x=  Embedding(num_encoder_tokens+1, 128)(encoder_inputs)  \n",
        "# en_x = Dropout(0.7)(en_x)   # dropout 추가\n",
        "# encoder_outputs, state_h, state_c = LSTM(128, return_sequences=True, recurrent_dropout = 0.3, return_state=True)(en_x)   \n",
        "# encoder_states=[state_h, state_c]   \n",
        "\n",
        "# ################################ 디코더 #################################\n",
        "# decoder_inputs = Input(shape=(fr_max_length,))\n",
        "# dex=  Embedding(num_decoder_tokens+1, 128)(decoder_inputs)\n",
        "# decoder = Dropout(0.7)(dex)\n",
        "# decoder = LSTM(128, recurrent_dropout = 0.3, return_sequences=True)(decoder, initial_state=encoder_states)   # 인코더 state와 연결!!\n",
        "\n",
        "\n",
        "# ################################ Attention Layer #################################\n",
        "# t = Dense(1000, activation='tanh', kernel_initializer='he_normal')(encoder_outputs)\n",
        "# t1 = Dense(1000, activation='tanh', kernel_initializer='he_normal')(decoder)\n",
        "\n",
        "# # dot product attention (유사도를 구하는 방법)\n",
        "# # attention 가중치를 value에 반영 (어텐션 score 계산) \n",
        "# # > 인코더의 모든 은닉상태 각각이 디코더의 현 시점 은닉상태 St와 얼마나 유사한지를 score로 나타냄\n",
        "# attention = dot([t1, t], axes=[2, 2])    # attention 가중치 계산 (Query와 Key의 유사도를 구함)\n",
        "\n",
        "# # attention = \n",
        "\n",
        "# attention = Dense(eng_max_length, activation='tanh', kernel_initializer='he_normal')(attention)  \n",
        "# attention = BatchNormalization(momentum=0.9)(attention)\n",
        "# attention = Activation('softmax')(attention)  # 가중치를 softmax 확률 값을 통해 인코더 output(value)에 전달!\n",
        "\n",
        "# context = dot([attention, encoder_outputs], axes = [2,1])  # 어텐션 value(가중합, product, weighted sum)\n",
        "\n",
        "# decoder_combined_context = concatenate([context, decoder])   # attention value와 디코더의 현재 은닉상태를 concat하여 하나의 벡터로 만듦 \n",
        "# decoder_combined_context = Dense(1000, activation='tanh', kernel_initializer='he_normal')(decoder_combined_context)\n",
        "# # decoder = Dropout(0.5)()\n",
        "\n",
        "# output = Dense( num_decoder_tokens+1, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.L1(0.0001))(decoder_combined_context)    # 출력층 (단어 확률값으로 출력)\n",
        "\n",
        "# model3 = Model(inputs=[encoder_inputs, decoder_inputs], outputs=[output])\n",
        "\n",
        "\n",
        "# ## ,  kernel_regularizer=tf.keras.regularizers.L1(0.01) 안좋음 > train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDcG7wu2qWdT",
        "outputId": "a515b612-041f-4118-b4a7-249c7954c3fc"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 8)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           [(None, 17)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 8, 256)       98816       input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 17, 256)      91904       input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 8, 256)       0           embedding_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 17, 256)      0           embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   [(None, 8, 256), (No 525312      dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_9 (LSTM)                   (None, 17, 256)      525312      dropout_9[0][0]                  \n",
            "                                                                 lstm_8[0][1]                     \n",
            "                                                                 lstm_8[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 17, 1500)     385500      lstm_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 8, 1500)      385500      lstm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dot_8 (Dot)                     (None, 17, 8)        0           dense_21[0][0]                   \n",
            "                                                                 dense_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 17, 8)        72          dot_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 17, 8)        0           dense_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dot_9 (Dot)                     (None, 17, 256)      0           activation_4[0][0]               \n",
            "                                                                 lstm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 17, 512)      0           dot_9[0][0]                      \n",
            "                                                                 lstm_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 17, 1000)     513000      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 17, 359)      359359      dense_23[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,884,775\n",
            "Trainable params: 2,884,775\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUcBRTs4E5P_",
        "outputId": "0005cfef-61c3-4773-acf6-f643089683af"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 17)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 8, 256)       98816       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 17, 256)      91904       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 8, 256)       0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 17, 256)      0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 8, 256), (No 525312      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 17, 256)      525312      dropout_1[0][0]                  \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 17, 5000)     1285000     lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 8, 5000)      1285000     lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 17, 8)        0           dense_1[0][0]                    \n",
            "                                                                 dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 17, 8)        72          dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 17, 8)        0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 17, 256)      0           activation[0][0]                 \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 17, 512)      0           dot_1[0][0]                      \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 17, 2000)     1026000     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 17, 359)      718359      dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 5,555,775\n",
            "Trainable params: 5,555,775\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF5bgIFETzfE"
      },
      "source": [
        "model3.compile(optimizer='adam', loss='categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocqJw1y3E5Ju",
        "outputId": "7311f2cf-2647-4300-e0eb-8e27ed4e47d1"
      },
      "source": [
        "history3 = model3.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=32,\n",
        "          epochs=5,\n",
        "          validation_split=0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1547/1547 [==============================] - 25s 14ms/step - loss: 0.9883 - accuracy: 0.8219 - val_loss: 0.6518 - val_accuracy: 0.8367\n",
            "Epoch 2/5\n",
            "1547/1547 [==============================] - 20s 13ms/step - loss: 0.4390 - accuracy: 0.8886 - val_loss: 0.5206 - val_accuracy: 0.8644\n",
            "Epoch 3/5\n",
            "1547/1547 [==============================] - 20s 13ms/step - loss: 0.3520 - accuracy: 0.9051 - val_loss: 0.4837 - val_accuracy: 0.8706\n",
            "Epoch 4/5\n",
            "1547/1547 [==============================] - 20s 13ms/step - loss: 0.3118 - accuracy: 0.9126 - val_loss: 0.4790 - val_accuracy: 0.8699\n",
            "Epoch 5/5\n",
            "1547/1547 [==============================] - 20s 13ms/step - loss: 0.2879 - accuracy: 0.9177 - val_loss: 0.4591 - val_accuracy: 0.8794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN96vlcAJjYF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "fbc83cf5-36fc-4058-9dcc-a4caac349cad"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc=history3.history['accuracy']\n",
        "val_acc=history3.history['val_accuracy']\n",
        "loss=history3.history['loss']\n",
        "val_loss=history3.history['val_loss']\n",
        "epochs=range(1,len(acc)+1)\n",
        "plt.plot(epochs,acc,'b',label='training acc')\n",
        "plt.plot(epochs,val_acc,'bo',label='validation acc')\n",
        "plt.title('training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs,loss,'b',label='training loss')\n",
        "plt.plot(epochs,val_loss,'bo',label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk74zRzIJlAX"
      },
      "source": [
        "decoder_input_data_pred = np.zeros(\n",
        "    (len(lines.fr), fr_max_length),\n",
        "    dtype='float32')\n",
        "\n",
        "final_pred_att = []\n",
        "for i in range(2500):\n",
        "  word = 284\n",
        "  for j in range(17):\n",
        "    decoder_input_data_pred[(47500+i), j] = word\n",
        "    pred = model3.predict([encoder_input_data[(47500+i)].reshape(1,8),decoder_input_data_pred[47500+i].reshape(1,17)])\n",
        "    t = np.argmax(pred[0][j])\n",
        "    word = t\n",
        "    if word==89:\n",
        "      break\n",
        "  final_pred_att.append(list(decoder_input_data_pred[47500+i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7busalnKJk9g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0c654b-2504-45f1-c1eb-70551f057ea8"
      },
      "source": [
        "final_pred2_att = np.array(final_pred_att)\n",
        "count = 0\n",
        "correct_count = 0\n",
        "\n",
        "for i in range(2500):\n",
        "  correct_count += np.sum((decoder_input_data[47500+i]==final_pred2_att[i]) & (decoder_input_data[47500+i]!=89))\n",
        "  count += np.sum(decoder_input_data[47500+i]!=89)\n",
        "correct_count/count  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4925907321361296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orIBBoEFJk6x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09aab436-49fc-45f5-faff-b9164e2c314c"
      },
      "source": [
        "k = -2400\n",
        "t = model3.predict([encoder_input_data[k].reshape(1,encoder_input_data.shape[1]),decoder_input_data[k].reshape(1,decoder_input_data.shape[1])]).reshape(decoder_input_data.shape[1], num_decoder_tokens+1)\n",
        "\n",
        "for i in range(len(encoder_input_data[k])):\n",
        "  if int(encoder_input_data[k][i])!=0:\n",
        "    print(list(input_token_index.keys())[int(encoder_input_data[k][i]-1)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i\n",
            "feel\n",
            "like\n",
            "unk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFpYNi2RJuYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af5a5a2-c25e-4dc0-d997-ac31af8bf028"
      },
      "source": [
        "t2 = np.argmax(t,axis=1)\n",
        "for i in range(len(t2)):\n",
        "  if int(t2[i])!=0:\n",
        "    print(list(target_token_index.keys())[int(t2[i]-1)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "je\n",
            "unk\n",
            "unk\n",
            "unk\n",
            "end\n",
            "unk\n",
            "end\n",
            "end\n",
            "end\n",
            "end\n",
            "end\n",
            "end\n",
            "end\n",
            "end\n",
            "end\n",
            "end\n",
            "end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7HfpAsDJk4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d75d8ee-7bda-45ff-815f-afa5a6796c4f"
      },
      "source": [
        "t2 = decoder_input_data[k]\n",
        "for i in range(len(t2)):\n",
        "  if int(t2[i])!=0:\n",
        "    print(list(target_token_index.keys())[int(t2[i]-1)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start\n",
            "jai\n",
            "unk\n",
            "de\n",
            "faire\n",
            "la\n",
            "unk\n",
            "end\n",
            "end\n",
            "end\n",
            "end\n",
            "end\n",
            "end\n",
            "end\n",
            "end\n",
            "end\n",
            "end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aiNyHymsvoa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq6GBblrJkwx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxO3kicHJkt7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}